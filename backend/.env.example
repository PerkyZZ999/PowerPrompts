# LLM Provider Configuration
# Options: "openai" or "openrouter"
LLM_PROVIDER=openrouter

# OpenAI Configuration (only used if LLM_PROVIDER=openai)
OPENAI_API_KEY=your-openai-api-key-here

# OpenRouter Configuration (only used if LLM_PROVIDER=openrouter)
OPENROUTER_API_KEY=your-openrouter-api-key-here

# OpenRouter Provider Routing (Optimize for high throughput + good pricing)
# Based on gpt-oss-120b providers: Google Vertex ($0.15 input/$0.60 output), Groq ($0.15/$0.60), SambaNova ($0.14/$0.95)
# These caps ensure we get providers like Google Vertex (547.8 TPS), Groq (674.3 TPS), SambaNova (811.6 TPS)
# Values are in USD per 1M tokens (same format as OpenRouter API)
OPENROUTER_MAX_PROMPT_PRICE=0.20
OPENROUTER_MAX_COMPLETION_PRICE=1.00

# Server Configuration
PORT=8000
NODE_ENV=development

# Database Configuration
DATABASE_PATH=./data/powerprompts.db

# API Authentication
API_KEY=cG93ZXJwcm9tcHRz

# ChromaDB Configuration
CHROMA_PATH=./data/chroma

# Application Configuration
APP_NAME=PowerPrompts
APP_VERSION=1.0.0

# LLM Models Configuration
# Just add model IDs separated by commas (names/descriptions are auto-generated)
# For OpenRouter: use provider prefix (e.g., openai/gpt-4o, anthropic/claude-3.5-sonnet)
# For OpenAI: use model ID directly (e.g., gpt-4o, gpt-4-turbo)
# GPT-OSS-120B is recommended for speed (~500 TPS vs GPT-5's ~50 TPS)
AVAILABLE_MODELS=gpt-oss-120b,openai/gpt-5,openai/gpt-4o,openai/gpt-4o-mini,anthropic/claude-3.5-sonnet,google/gemini-pro-1.5,meta-llama/llama-3.1-70b-instruct
DEFAULT_MODEL=gpt-oss-120b
